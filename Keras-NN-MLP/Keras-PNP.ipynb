{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2091f0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import StandardScaler  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8f3080c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('data-stiffness_SS.xlsx') \n",
    "\n",
    "# remove rows with null value\n",
    "data = data.dropna(how='any',axis=0) \n",
    "\n",
    "# select features and target variable\n",
    "features = data.iloc[:, :-2]  # all columns except the last two\n",
    "\n",
    "#target = data.iloc[:, -2:-1]     # stiffness\n",
    "target = data.iloc[:, -1]     # specific stiffness\n",
    "\n",
    "X_train, X_valid, y_train, y_valid =train_test_split(features, target , test_size = 0.25,random_state=0, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b496dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling\n",
    "scaler = StandardScaler()  \n",
    "\n",
    "X_train = scaler.fit_transform(X_train)  # numpy.ndarray\n",
    "X_valid = scaler.transform(X_valid)      # numpy.ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffb22209",
   "metadata": {},
   "outputs": [],
   "source": [
    "#It builds and returns a feedforward neural network (a Sequential model) for regression tasks. \n",
    "#The model is customizable via its arguments, such as the number of hidden layers, the number of neurons in each layer, \n",
    "#and the learning rate for optimization.\n",
    "\n",
    "def build_model(n_hidden , n_neurons, learning_rate, shape, active_fun):\n",
    "    model = keras.models.Sequential()  \n",
    "    model.add(keras.layers.InputLayer(shape=shape))  \n",
    "    for layer in range(n_hidden):     \n",
    "        model.add(keras.layers.Dense(n_neurons , activation=active_fun)) \n",
    "    model.add(keras.layers.Dense(1))  \n",
    "    optimizer= keras.optimizers.Adam(learning_rate=learning_rate)  \n",
    "    model.compile(loss=\"mse\", optimizer=optimizer, metrics=[\"mse\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1dada83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build keras model\n",
    "model = build_model(n_hidden=4 , n_neurons=52, learning_rate=0.003, shape=[9], active_fun='tanh')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ab5f279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting callbacks\n",
    "\n",
    "early_stopping = keras.callbacks.EarlyStopping(patience=20,\n",
    "                                              restore_best_weights=False)       #patience: Number of epochs with no improvement after which training will be stopped. Defaults to 0.\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\"My_trained_model.keras\",\n",
    "                                                     save_best_only=False,\n",
    "                                                     monitor='val_loss',\n",
    "                                                     verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa399347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 1s/step - loss: 0.4913 - mse: 0.4913\n",
      "Epoch 1: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.2270 - mse: 0.2270 - val_loss: 0.0231 - val_mse: 0.0231\n",
      "Epoch 2/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0243 - mse: 0.0243\n",
      "Epoch 2: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0261 - mse: 0.0261 - val_loss: 0.0184 - val_mse: 0.0184\n",
      "Epoch 3/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0153 - mse: 0.0153\n",
      "Epoch 3: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 4/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0080 - mse: 0.0080\n",
      "Epoch 4: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0104 - mse: 0.0104 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 5/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0099 - mse: 0.0099\n",
      "Epoch 5: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0087 - mse: 0.0087 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 6/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0046 - mse: 0.0046\n",
      "Epoch 6: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0088 - val_mse: 0.0088\n",
      "Epoch 7/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0044 - mse: 0.0044\n",
      "Epoch 7: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0072 - val_mse: 0.0072\n",
      "Epoch 8/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0042 - mse: 0.0042\n",
      "Epoch 8: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0045 - mse: 0.0045 - val_loss: 0.0068 - val_mse: 0.0068\n",
      "Epoch 9/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0056 - mse: 0.0056\n",
      "Epoch 9: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0043 - mse: 0.0043 - val_loss: 0.0065 - val_mse: 0.0065\n",
      "Epoch 10/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0073 - mse: 0.0073\n",
      "Epoch 10: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0046 - mse: 0.0046 - val_loss: 0.0071 - val_mse: 0.0071\n",
      "Epoch 11/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0040 - mse: 0.0040\n",
      "Epoch 11: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0043 - mse: 0.0043 - val_loss: 0.0064 - val_mse: 0.0064\n",
      "Epoch 12/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0045 - mse: 0.0045\n",
      "Epoch 12: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0044 - mse: 0.0044 - val_loss: 0.0049 - val_mse: 0.0049\n",
      "Epoch 13/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0015 - mse: 0.0015\n",
      "Epoch 13: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0028 - mse: 0.0028 - val_loss: 0.0057 - val_mse: 0.0057\n",
      "Epoch 14/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0026 - mse: 0.0026\n",
      "Epoch 14: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0034 - mse: 0.0034 - val_loss: 0.0062 - val_mse: 0.0062\n",
      "Epoch 15/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0052 - mse: 0.0052\n",
      "Epoch 15: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0053 - val_mse: 0.0053\n",
      "Epoch 16/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0014 - mse: 0.0014\n",
      "Epoch 16: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0025 - mse: 0.0025 - val_loss: 0.0051 - val_mse: 0.0051\n",
      "Epoch 17/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0029 - mse: 0.0029\n",
      "Epoch 17: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0029 - mse: 0.0029 - val_loss: 0.0052 - val_mse: 0.0052\n",
      "Epoch 18/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0019 - mse: 0.0019\n",
      "Epoch 18: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0028 - mse: 0.0028 - val_loss: 0.0054 - val_mse: 0.0054\n",
      "Epoch 19/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0021 - mse: 0.0021\n",
      "Epoch 19: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 0.0046 - val_mse: 0.0046\n",
      "Epoch 20/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0012 - mse: 0.0012\n",
      "Epoch 20: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0056 - val_mse: 0.0056\n",
      "Epoch 21/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0019 - mse: 0.0019\n",
      "Epoch 21: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0029 - mse: 0.0029 - val_loss: 0.0052 - val_mse: 0.0052\n",
      "Epoch 22/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0044 - mse: 0.0044\n",
      "Epoch 22: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0035 - mse: 0.0035 - val_loss: 0.0050 - val_mse: 0.0050\n",
      "Epoch 23/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0034 - mse: 0.0034\n",
      "Epoch 23: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 0.0041 - val_mse: 0.0041\n",
      "Epoch 24/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0031 - mse: 0.0031\n",
      "Epoch 24: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 0.0036 - val_mse: 0.0036\n",
      "Epoch 25/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0022 - mse: 0.0022\n",
      "Epoch 25: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 0.0047 - val_mse: 0.0047\n",
      "Epoch 26/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0020 - mse: 0.0020\n",
      "Epoch 26: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 0.0035 - val_mse: 0.0035\n",
      "Epoch 27/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0027 - mse: 0.0027\n",
      "Epoch 27: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 0.0041 - val_mse: 0.0041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0031 - mse: 0.0031\n",
      "Epoch 28: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0025 - mse: 0.0025 - val_loss: 0.0054 - val_mse: 0.0054\n",
      "Epoch 29/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0016 - mse: 0.0016\n",
      "Epoch 29: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 0.0042 - val_mse: 0.0042\n",
      "Epoch 30/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0013 - mse: 0.0013\n",
      "Epoch 30: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0035 - val_mse: 0.0035\n",
      "Epoch 31/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0013 - mse: 0.0013\n",
      "Epoch 31: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0071 - val_mse: 0.0071\n",
      "Epoch 32/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 32: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 0.0052 - val_mse: 0.0052\n",
      "Epoch 33/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0018 - mse: 0.0018\n",
      "Epoch 33: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 0.0034 - val_mse: 0.0034\n",
      "Epoch 34/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0020 - mse: 0.0020\n",
      "Epoch 34: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0037 - val_mse: 0.0037\n",
      "Epoch 35/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0023 - mse: 0.0023\n",
      "Epoch 35: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0048 - val_mse: 0.0048\n",
      "Epoch 36/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 8.0339e-04 - mse: 8.0339e-04\n",
      "Epoch 36: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0032 - val_mse: 0.0032\n",
      "Epoch 37/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0013 - mse: 0.0013\n",
      "Epoch 37: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0044 - val_mse: 0.0044\n",
      "Epoch 38/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 38: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 0.0045 - val_mse: 0.0045\n",
      "Epoch 39/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0031 - mse: 0.0031\n",
      "Epoch 39: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 0.0042 - val_mse: 0.0042\n",
      "Epoch 40/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0040 - mse: 0.0040\n",
      "Epoch 40: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0028 - mse: 0.0028 - val_loss: 0.0043 - val_mse: 0.0043\n",
      "Epoch 41/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0030 - mse: 0.0030\n",
      "Epoch 41: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 0.0035 - val_mse: 0.0035\n",
      "Epoch 42/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0021 - mse: 0.0021\n",
      "Epoch 42: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0045 - val_mse: 0.0045\n",
      "Epoch 43/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 43: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0048 - val_mse: 0.0048\n",
      "Epoch 44/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0028 - mse: 0.0028\n",
      "Epoch 44: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0030 - val_mse: 0.0030\n",
      "Epoch 45/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0014 - mse: 0.0014\n",
      "Epoch 45: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0035 - val_mse: 0.0035\n",
      "Epoch 46/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0013 - mse: 0.0013\n",
      "Epoch 46: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0040 - val_mse: 0.0040\n",
      "Epoch 47/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0011 - mse: 0.0011\n",
      "Epoch 47: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0035 - val_mse: 0.0035\n",
      "Epoch 48/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0019 - mse: 0.0019\n",
      "Epoch 48: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0044 - val_mse: 0.0044\n",
      "Epoch 49/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0015 - mse: 0.0015\n",
      "Epoch 49: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0034 - val_mse: 0.0034\n",
      "Epoch 50/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0015 - mse: 0.0015\n",
      "Epoch 50: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0033 - val_mse: 0.0033\n",
      "Epoch 51/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0015 - mse: 0.0015\n",
      "Epoch 51: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0034 - val_mse: 0.0034\n",
      "Epoch 52/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0021 - mse: 0.0021\n",
      "Epoch 52: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0039 - val_mse: 0.0039\n",
      "Epoch 53/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0011 - mse: 0.0011\n",
      "Epoch 53: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0042 - val_mse: 0.0042\n",
      "Epoch 54/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0019 - mse: 0.0019\n",
      "Epoch 54: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0032 - val_mse: 0.0032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 55: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0036 - val_mse: 0.0036\n",
      "Epoch 56/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 7.4862e-04 - mse: 7.4862e-04\n",
      "Epoch 56: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0032 - val_mse: 0.0032\n",
      "Epoch 57/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0011 - mse: 0.0011\n",
      "Epoch 57: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0041 - val_mse: 0.0041\n",
      "Epoch 58/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0015 - mse: 0.0015\n",
      "Epoch 58: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0034 - val_mse: 0.0034\n",
      "Epoch 59/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0012 - mse: 0.0012\n",
      "Epoch 59: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0030 - val_mse: 0.0030\n",
      "Epoch 60/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 9.3255e-04 - mse: 9.3255e-04\n",
      "Epoch 60: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0041 - val_mse: 0.0041\n",
      "Epoch 61/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0026 - mse: 0.0026\n",
      "Epoch 61: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0032 - val_mse: 0.0032\n",
      "Epoch 62/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 9.0771e-04 - mse: 9.0771e-04\n",
      "Epoch 62: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0032 - val_mse: 0.0032\n",
      "Epoch 63/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0010 - mse: 0.0010\n",
      "Epoch 63: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0034 - val_mse: 0.0034\n",
      "Epoch 64/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0022 - mse: 0.0022\n",
      "Epoch 64: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0039 - val_mse: 0.0039\n",
      "Epoch 65/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0025 - mse: 0.0025\n",
      "Epoch 65: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0044 - val_mse: 0.0044\n",
      "Epoch 66/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0033 - mse: 0.0033\n",
      "Epoch 66: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 0.0040 - val_mse: 0.0040\n",
      "Epoch 67/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0015 - mse: 0.0015\n",
      "Epoch 67: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 0.0028 - val_mse: 0.0028\n",
      "Epoch 68/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0011 - mse: 0.0011\n",
      "Epoch 68: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0040 - val_mse: 0.0040\n",
      "Epoch 69/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0019 - mse: 0.0019\n",
      "Epoch 69: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0036 - val_mse: 0.0036\n",
      "Epoch 70/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 70: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0036 - val_mse: 0.0036\n",
      "Epoch 71/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0016 - mse: 0.0016\n",
      "Epoch 71: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0034 - val_mse: 0.0034\n",
      "Epoch 72/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 72: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0037 - val_mse: 0.0037\n",
      "Epoch 73/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0016 - mse: 0.0016\n",
      "Epoch 73: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0028 - val_mse: 0.0028\n",
      "Epoch 74/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 9.3823e-04 - mse: 9.3823e-04\n",
      "Epoch 74: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0028 - val_mse: 0.0028\n",
      "Epoch 75/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 4.3084e-04 - mse: 4.3084e-04\n",
      "Epoch 75: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.8196e-04 - mse: 9.8196e-04 - val_loss: 0.0035 - val_mse: 0.0035\n",
      "Epoch 76/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0014 - mse: 0.0014\n",
      "Epoch 76: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0028 - val_mse: 0.0028\n",
      "Epoch 77/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0018 - mse: 0.0018\n",
      "Epoch 77: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0038 - val_mse: 0.0038\n",
      "Epoch 78/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0024 - mse: 0.0024\n",
      "Epoch 78: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0034 - val_mse: 0.0034\n",
      "Epoch 79/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0016 - mse: 0.0016\n",
      "Epoch 79: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0047 - val_mse: 0.0047\n",
      "Epoch 80/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0013 - mse: 0.0013\n",
      "Epoch 80: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0030 - val_mse: 0.0030\n",
      "Epoch 81/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0021 - mse: 0.0021\n",
      "Epoch 81: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0029 - val_mse: 0.0029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 6.8799e-04 - mse: 6.8799e-04\n",
      "Epoch 82: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.4984e-04 - mse: 7.4984e-04 - val_loss: 0.0034 - val_mse: 0.0034\n",
      "Epoch 83/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0013 - mse: 0.0013\n",
      "Epoch 83: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0031 - val_mse: 0.0031\n",
      "Epoch 84/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 8.4232e-04 - mse: 8.4232e-04\n",
      "Epoch 84: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0046 - val_mse: 0.0046\n",
      "Epoch 85/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0029 - mse: 0.0029\n",
      "Epoch 85: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 0.0044 - val_mse: 0.0044\n",
      "Epoch 86/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0022 - mse: 0.0022\n",
      "Epoch 86: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0030 - val_mse: 0.0030\n",
      "Epoch 87/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 6.9892e-04 - mse: 6.9892e-04\n",
      "Epoch 87: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.5209e-04 - mse: 8.5209e-04 - val_loss: 0.0030 - val_mse: 0.0030\n",
      "Epoch 88/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 9.8487e-04 - mse: 9.8487e-04\n",
      "Epoch 88: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0030 - val_mse: 0.0030\n",
      "Epoch 89/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0011 - mse: 0.0011\n",
      "Epoch 89: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0030 - val_mse: 0.0030\n",
      "Epoch 90/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0010 - mse: 0.0010\n",
      "Epoch 90: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.3352e-04 - mse: 7.3352e-04 - val_loss: 0.0026 - val_mse: 0.0026\n",
      "Epoch 91/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 3.6326e-04 - mse: 3.6326e-04\n",
      "Epoch 91: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.7037e-04 - mse: 8.7037e-04 - val_loss: 0.0026 - val_mse: 0.0026\n",
      "Epoch 92/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 7.9068e-04 - mse: 7.9068e-04\n",
      "Epoch 92: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0029 - val_mse: 0.0029\n",
      "Epoch 93/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0013 - mse: 0.0013\n",
      "Epoch 93: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0025 - val_mse: 0.0025\n",
      "Epoch 94/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0014 - mse: 0.0014\n",
      "Epoch 94: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0033 - val_mse: 0.0033\n",
      "Epoch 95/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0012 - mse: 0.0012\n",
      "Epoch 95: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0032 - val_mse: 0.0032\n",
      "Epoch 96/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0012 - mse: 0.0012\n",
      "Epoch 96: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.9671e-04 - mse: 8.9671e-04 - val_loss: 0.0026 - val_mse: 0.0026\n",
      "Epoch 97/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 7.1774e-04 - mse: 7.1774e-04\n",
      "Epoch 97: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.6462e-04 - mse: 8.6462e-04 - val_loss: 0.0027 - val_mse: 0.0027\n",
      "Epoch 98/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 5.2121e-04 - mse: 5.2121e-04\n",
      "Epoch 98: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.7469e-04 - mse: 7.7469e-04 - val_loss: 0.0029 - val_mse: 0.0029\n",
      "Epoch 99/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 5.6588e-04 - mse: 5.6588e-04\n",
      "Epoch 99: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0031 - val_mse: 0.0031\n",
      "Epoch 100/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 6.6988e-04 - mse: 6.6988e-04\n",
      "Epoch 100: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.5401e-04 - mse: 9.5401e-04 - val_loss: 0.0026 - val_mse: 0.0026\n",
      "Epoch 101/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 6.0940e-04 - mse: 6.0940e-04\n",
      "Epoch 101: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.3467e-04 - mse: 7.3467e-04 - val_loss: 0.0030 - val_mse: 0.0030\n",
      "Epoch 102/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0011 - mse: 0.0011\n",
      "Epoch 102: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0032 - val_mse: 0.0032\n",
      "Epoch 103/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0010 - mse: 0.0010\n",
      "Epoch 103: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0025 - mse: 0.0025 - val_loss: 0.0049 - val_mse: 0.0049\n",
      "Epoch 104/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0015 - mse: 0.0015\n",
      "Epoch 104: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 0.0027 - val_mse: 0.0027\n",
      "Epoch 105/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0019 - mse: 0.0019\n",
      "Epoch 105: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0023 - val_mse: 0.0023\n",
      "Epoch 106/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 4.3991e-04 - mse: 4.3991e-04\n",
      "Epoch 106: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0024 - val_mse: 0.0024\n",
      "Epoch 107/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 3.9016e-04 - mse: 3.9016e-04\n",
      "Epoch 107: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.3090e-04 - mse: 6.3090e-04 - val_loss: 0.0031 - val_mse: 0.0031\n",
      "Epoch 108/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0011 - mse: 0.0011\n",
      "Epoch 108: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.2495e-04 - mse: 9.2495e-04 - val_loss: 0.0028 - val_mse: 0.0028\n",
      "Epoch 109/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0011 - mse: 0.0011\n",
      "Epoch 109: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0022 - val_mse: 0.0022\n",
      "Epoch 110/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 3.4978e-04 - mse: 3.4978e-04\n",
      "Epoch 110: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0043 - val_mse: 0.0043\n",
      "Epoch 111/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0021 - mse: 0.0021\n",
      "Epoch 111: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0045 - val_mse: 0.0045\n",
      "Epoch 112/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0023 - mse: 0.0023\n",
      "Epoch 112: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0023 - val_mse: 0.0023\n",
      "Epoch 113/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 9.1832e-04 - mse: 9.1832e-04\n",
      "Epoch 113: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.6562e-04 - mse: 9.6562e-04 - val_loss: 0.0030 - val_mse: 0.0030\n",
      "Epoch 114/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0011 - mse: 0.0011\n",
      "Epoch 114: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.5224e-04 - mse: 8.5224e-04 - val_loss: 0.0028 - val_mse: 0.0028\n",
      "Epoch 115/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0016 - mse: 0.0016\n",
      "Epoch 115: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0026 - val_mse: 0.0026\n",
      "Epoch 116/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0012 - mse: 0.0012\n",
      "Epoch 116: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.2744e-04 - mse: 8.2744e-04 - val_loss: 0.0032 - val_mse: 0.0032\n",
      "Epoch 117/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0011 - mse: 0.0011\n",
      "Epoch 117: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.2034e-04 - mse: 9.2034e-04 - val_loss: 0.0025 - val_mse: 0.0025\n",
      "Epoch 118/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 8.0949e-04 - mse: 8.0949e-04\n",
      "Epoch 118: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.8651e-04 - mse: 6.8651e-04 - val_loss: 0.0023 - val_mse: 0.0023\n",
      "Epoch 119/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 4.8866e-04 - mse: 4.8866e-04\n",
      "Epoch 119: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.8276e-04 - mse: 5.8276e-04 - val_loss: 0.0030 - val_mse: 0.0030\n",
      "Epoch 120/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0015 - mse: 0.0015\n",
      "Epoch 120: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.5167e-04 - mse: 9.5167e-04 - val_loss: 0.0038 - val_mse: 0.0038\n",
      "Epoch 121/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 6.6544e-04 - mse: 6.6544e-04\n",
      "Epoch 121: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.5464e-04 - mse: 7.5464e-04 - val_loss: 0.0025 - val_mse: 0.0025\n",
      "Epoch 122/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 7.8223e-04 - mse: 7.8223e-04\n",
      "Epoch 122: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.6949e-04 - mse: 8.6949e-04 - val_loss: 0.0029 - val_mse: 0.0029\n",
      "Epoch 123/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0016 - mse: 0.0016\n",
      "Epoch 123: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0032 - val_mse: 0.0032\n",
      "Epoch 124/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0019 - mse: 0.0019\n",
      "Epoch 124: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0022 - val_mse: 0.0022\n",
      "Epoch 125/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 6.0582e-04 - mse: 6.0582e-04\n",
      "Epoch 125: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.5378e-04 - mse: 9.5378e-04 - val_loss: 0.0024 - val_mse: 0.0024\n",
      "Epoch 126/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0015 - mse: 0.0015\n",
      "Epoch 126: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0010 - mse: 0.0010 - val_loss: 0.0026 - val_mse: 0.0026\n",
      "Epoch 127/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0012 - mse: 0.0012\n",
      "Epoch 127: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0028 - val_mse: 0.0028\n",
      "Epoch 128/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0013 - mse: 0.0013\n",
      "Epoch 128: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0020 - val_mse: 0.0020\n",
      "Epoch 129/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 6.4194e-04 - mse: 6.4194e-04\n",
      "Epoch 129: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.5255e-04 - mse: 6.5255e-04 - val_loss: 0.0028 - val_mse: 0.0028\n",
      "Epoch 130/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 8.7952e-04 - mse: 8.7952e-04\n",
      "Epoch 130: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.8081e-04 - mse: 8.8081e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
      "Epoch 131/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 4.8831e-04 - mse: 4.8831e-04\n",
      "Epoch 131: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.7645e-04 - mse: 6.7645e-04 - val_loss: 0.0028 - val_mse: 0.0028\n",
      "Epoch 132/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0010 - mse: 0.0010\n",
      "Epoch 132: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.7351e-04 - mse: 6.7351e-04 - val_loss: 0.0022 - val_mse: 0.0022\n",
      "Epoch 133/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 7.1058e-04 - mse: 7.1058e-04\n",
      "Epoch 133: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.1042e-04 - mse: 7.1042e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
      "Epoch 134/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 6.4026e-04 - mse: 6.4026e-04\n",
      "Epoch 134: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0027 - val_mse: 0.0027\n",
      "Epoch 135/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 3.9760e-04 - mse: 3.9760e-04\n",
      "Epoch 135: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0036 - val_mse: 0.0036\n",
      "Epoch 136/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0010 - mse: 0.0010\n",
      "Epoch 136: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0021 - val_mse: 0.0021\n",
      "Epoch 137/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 6.4530e-04 - mse: 6.4530e-04\n",
      "Epoch 137: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.9703e-04 - mse: 7.9703e-04 - val_loss: 0.0025 - val_mse: 0.0025\n",
      "Epoch 138/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 8.7931e-04 - mse: 8.7931e-04\n",
      "Epoch 138: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.6907e-04 - mse: 8.6907e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
      "Epoch 139/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 4.4224e-04 - mse: 4.4224e-04\n",
      "Epoch 139: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.4233e-04 - mse: 5.4233e-04 - val_loss: 0.0023 - val_mse: 0.0023\n",
      "Epoch 140/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 3.2055e-04 - mse: 3.2055e-04\n",
      "Epoch 140: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.4674e-04 - mse: 8.4674e-04 - val_loss: 0.0026 - val_mse: 0.0026\n",
      "Epoch 141/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0013 - mse: 0.0013\n",
      "Epoch 141: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0026 - val_mse: 0.0026\n",
      "Epoch 142/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0019 - mse: 0.0019\n",
      "Epoch 142: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0027 - val_mse: 0.0027\n",
      "Epoch 143/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 5.2816e-04 - mse: 5.2816e-04\n",
      "Epoch 143: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0021 - val_mse: 0.0021\n",
      "Epoch 144/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 6.4583e-04 - mse: 6.4583e-04\n",
      "Epoch 144: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.4302e-04 - mse: 7.4302e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
      "Epoch 145/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 4.1799e-04 - mse: 4.1799e-04\n",
      "Epoch 145: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.4239e-04 - mse: 5.4239e-04 - val_loss: 0.0025 - val_mse: 0.0025\n",
      "Epoch 146/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 4.5248e-04 - mse: 4.5248e-04\n",
      "Epoch 146: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.1508e-04 - mse: 7.1508e-04 - val_loss: 0.0033 - val_mse: 0.0033\n",
      "Epoch 147/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 8.2779e-04 - mse: 8.2779e-04\n",
      "Epoch 147: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0052 - val_mse: 0.0052\n",
      "Epoch 148/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0025 - mse: 0.0025\n",
      "Epoch 148: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0026 - val_mse: 0.0026\n",
      "Epoch 149/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0012 - mse: 0.0012\n",
      "Epoch 149: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0010 - mse: 0.0010 - val_loss: 0.0024 - val_mse: 0.0024\n",
      "Epoch 150/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 5.3663e-04 - mse: 5.3663e-04\n",
      "Epoch 150: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.9928e-04 - mse: 5.9928e-04 - val_loss: 0.0020 - val_mse: 0.0020\n",
      "Epoch 151/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 4.6468e-04 - mse: 4.6468e-04\n",
      "Epoch 151: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.2295e-04 - mse: 4.2295e-04 - val_loss: 0.0022 - val_mse: 0.0022\n",
      "Epoch 152/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 3.7889e-04 - mse: 3.7889e-04\n",
      "Epoch 152: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.6743e-04 - mse: 5.6743e-04 - val_loss: 0.0022 - val_mse: 0.0022\n",
      "Epoch 153/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 6.4344e-04 - mse: 6.4344e-04\n",
      "Epoch 153: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.6625e-04 - mse: 7.6625e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
      "Epoch 154/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 5.5847e-04 - mse: 5.5847e-04\n",
      "Epoch 154: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.4064e-04 - mse: 5.4064e-04 - val_loss: 0.0020 - val_mse: 0.0020\n",
      "Epoch 155/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 6.4453e-04 - mse: 6.4453e-04\n",
      "Epoch 155: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.0278e-04 - mse: 6.0278e-04 - val_loss: 0.0025 - val_mse: 0.0025\n",
      "Epoch 156/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 6.4050e-04 - mse: 6.4050e-04\n",
      "Epoch 156: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.8107e-04 - mse: 5.8107e-04 - val_loss: 0.0021 - val_mse: 0.0021\n",
      "Epoch 157/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 5.1292e-04 - mse: 5.1292e-04\n",
      "Epoch 157: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.9931e-04 - mse: 4.9931e-04 - val_loss: 0.0015 - val_mse: 0.0015\n",
      "Epoch 158/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 4.4016e-04 - mse: 4.4016e-04\n",
      "Epoch 158: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.5270e-04 - mse: 4.5270e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
      "Epoch 159/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 4.0240e-04 - mse: 4.0240e-04\n",
      "Epoch 159: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.5760e-04 - mse: 6.5760e-04 - val_loss: 0.0018 - val_mse: 0.0018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 160/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 6.0950e-04 - mse: 6.0950e-04\n",
      "Epoch 160: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.2092e-04 - mse: 6.2092e-04 - val_loss: 0.0021 - val_mse: 0.0021\n",
      "Epoch 161/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 5.2079e-04 - mse: 5.2079e-04\n",
      "Epoch 161: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.0699e-04 - mse: 6.0699e-04 - val_loss: 0.0017 - val_mse: 0.0017\n",
      "Epoch 162/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 6.2336e-04 - mse: 6.2336e-04\n",
      "Epoch 162: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.9239e-04 - mse: 5.9239e-04 - val_loss: 0.0015 - val_mse: 0.0015\n",
      "Epoch 163/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 4.4401e-04 - mse: 4.4401e-04\n",
      "Epoch 163: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.0045e-04 - mse: 5.0045e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
      "Epoch 164/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 4.0459e-04 - mse: 4.0459e-04\n",
      "Epoch 164: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.5412e-04 - mse: 4.5412e-04 - val_loss: 0.0020 - val_mse: 0.0020\n",
      "Epoch 165/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 3.6199e-04 - mse: 3.6199e-04\n",
      "Epoch 165: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.3618e-04 - mse: 6.3618e-04 - val_loss: 0.0020 - val_mse: 0.0020\n",
      "Epoch 166/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 5.4853e-04 - mse: 5.4853e-04\n",
      "Epoch 166: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0023 - val_mse: 0.0023\n",
      "Epoch 167/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 8.6713e-04 - mse: 8.6713e-04\n",
      "Epoch 167: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.7007e-04 - mse: 7.7007e-04 - val_loss: 0.0020 - val_mse: 0.0020\n",
      "Epoch 168/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0011 - mse: 0.0011\n",
      "Epoch 168: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.9440e-04 - mse: 7.9440e-04 - val_loss: 0.0017 - val_mse: 0.0017\n",
      "Epoch 169/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 5.0555e-04 - mse: 5.0555e-04\n",
      "Epoch 169: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.4511e-04 - mse: 5.4511e-04 - val_loss: 0.0022 - val_mse: 0.0022\n",
      "Epoch 170/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0013 - mse: 0.0013\n",
      "Epoch 170: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0010 - mse: 0.0010 - val_loss: 0.0022 - val_mse: 0.0022\n",
      "Epoch 171/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 9.7006e-04 - mse: 9.7006e-04\n",
      "Epoch 171: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0026 - val_mse: 0.0026\n",
      "Epoch 172/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0010 - mse: 0.0010\n",
      "Epoch 172: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0023 - val_mse: 0.0023\n",
      "Epoch 173/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 173: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 0.0045 - val_mse: 0.0045\n",
      "Epoch 174/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 8.3683e-04 - mse: 8.3683e-04\n",
      "Epoch 174: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0026 - val_mse: 0.0026\n",
      "Epoch 175/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0014 - mse: 0.0014\n",
      "Epoch 175: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0020 - val_mse: 0.0020\n",
      "Epoch 176/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 8.2450e-04 - mse: 8.2450e-04\n",
      "Epoch 176: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.8599e-04 - mse: 7.8599e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
      "Epoch 177/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 7.3977e-04 - mse: 7.3977e-04\n",
      "Epoch 177: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.8396e-04 - mse: 6.8396e-04 - val_loss: 0.0022 - val_mse: 0.0022\n",
      "Epoch 178/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 4.9229e-04 - mse: 4.9229e-04\n",
      "Epoch 178: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.8247e-04 - mse: 4.8247e-04 - val_loss: 0.0016 - val_mse: 0.0016\n",
      "Epoch 179/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 3.6250e-04 - mse: 3.6250e-04\n",
      "Epoch 179: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.1382e-04 - mse: 4.1382e-04 - val_loss: 0.0021 - val_mse: 0.0021\n",
      "Epoch 180/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 5.2096e-04 - mse: 5.2096e-04\n",
      "Epoch 180: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.9348e-04 - mse: 6.9348e-04 - val_loss: 0.0024 - val_mse: 0.0024\n",
      "Epoch 181/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 6.6977e-04 - mse: 6.6977e-04\n",
      "Epoch 181: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.0781e-04 - mse: 7.0781e-04 - val_loss: 0.0020 - val_mse: 0.0020\n",
      "Epoch 182/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 4.9107e-04 - mse: 4.9107e-04\n",
      "Epoch 182: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.5148e-04 - mse: 5.5148e-04 - val_loss: 0.0015 - val_mse: 0.0015\n",
      "Epoch 183/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 9.3833e-04 - mse: 9.3833e-04\n",
      "Epoch 183: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.8638e-04 - mse: 6.8638e-04 - val_loss: 0.0017 - val_mse: 0.0017\n",
      "Epoch 184/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 4.1785e-04 - mse: 4.1785e-04\n",
      "Epoch 184: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.0964e-04 - mse: 4.0964e-04 - val_loss: 0.0014 - val_mse: 0.0014\n",
      "Epoch 185/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 2.3617e-04 - mse: 2.3617e-04\n",
      "Epoch 185: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.7979e-04 - mse: 2.7979e-04 - val_loss: 0.0018 - val_mse: 0.0018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 186/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 2.3075e-04 - mse: 2.3075e-04\n",
      "Epoch 186: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.4693e-04 - mse: 3.4693e-04 - val_loss: 0.0014 - val_mse: 0.0014\n",
      "Epoch 187/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.8769e-04 - mse: 1.8769e-04\n",
      "Epoch 187: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.2640e-04 - mse: 4.2640e-04 - val_loss: 0.0015 - val_mse: 0.0015\n",
      "Epoch 188/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 2.8945e-04 - mse: 2.8945e-04\n",
      "Epoch 188: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.2701e-04 - mse: 3.2701e-04 - val_loss: 0.0013 - val_mse: 0.0013\n",
      "Epoch 189/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 3.1612e-04 - mse: 3.1612e-04\n",
      "Epoch 189: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.5633e-04 - mse: 3.5633e-04 - val_loss: 0.0014 - val_mse: 0.0014\n",
      "Epoch 190/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 2.9117e-04 - mse: 2.9117e-04\n",
      "Epoch 190: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.8240e-04 - mse: 3.8240e-04 - val_loss: 0.0031 - val_mse: 0.0031\n",
      "Epoch 191/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0019 - mse: 0.0019\n",
      "Epoch 191: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.5952e-04 - mse: 9.5952e-04 - val_loss: 0.0025 - val_mse: 0.0025\n",
      "Epoch 192/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0014 - mse: 0.0014\n",
      "Epoch 192: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0010 - mse: 0.0010 - val_loss: 0.0017 - val_mse: 0.0017\n",
      "Epoch 193/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 9.1920e-04 - mse: 9.1920e-04\n",
      "Epoch 193: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.7480e-04 - mse: 5.7480e-04 - val_loss: 0.0017 - val_mse: 0.0017\n",
      "Epoch 194/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0013 - mse: 0.0013\n",
      "Epoch 194: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.8390e-04 - mse: 6.8390e-04 - val_loss: 0.0016 - val_mse: 0.0016\n",
      "Epoch 195/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 5.1421e-04 - mse: 5.1421e-04\n",
      "Epoch 195: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.4094e-04 - mse: 6.4094e-04 - val_loss: 0.0017 - val_mse: 0.0017\n",
      "Epoch 196/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 4.3860e-04 - mse: 4.3860e-04\n",
      "Epoch 196: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.1529e-04 - mse: 8.1529e-04 - val_loss: 0.0026 - val_mse: 0.0026\n",
      "Epoch 197/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 6.1504e-04 - mse: 6.1504e-04\n",
      "Epoch 197: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.9323e-04 - mse: 5.9323e-04 - val_loss: 0.0017 - val_mse: 0.0017\n",
      "Epoch 198/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 7.2897e-04 - mse: 7.2897e-04\n",
      "Epoch 198: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.2675e-04 - mse: 5.2675e-04 - val_loss: 0.0014 - val_mse: 0.0014\n",
      "Epoch 199/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 4.8434e-04 - mse: 4.8434e-04\n",
      "Epoch 199: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.1545e-04 - mse: 5.1545e-04 - val_loss: 0.0016 - val_mse: 0.0016\n",
      "Epoch 200/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 2.5458e-04 - mse: 2.5458e-04\n",
      "Epoch 200: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.0124e-04 - mse: 3.0124e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
      "Epoch 201/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 3.9134e-04 - mse: 3.9134e-04\n",
      "Epoch 201: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.5006e-04 - mse: 3.5006e-04 - val_loss: 0.0017 - val_mse: 0.0017\n",
      "Epoch 202/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 7.4730e-04 - mse: 7.4730e-04\n",
      "Epoch 202: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.2511e-04 - mse: 6.2511e-04 - val_loss: 0.0014 - val_mse: 0.0014\n",
      "Epoch 203/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 2.6094e-04 - mse: 2.6094e-04\n",
      "Epoch 203: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.7638e-04 - mse: 4.7638e-04 - val_loss: 0.0015 - val_mse: 0.0015\n",
      "Epoch 204/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 5.9587e-04 - mse: 5.9587e-04\n",
      "Epoch 204: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.9763e-04 - mse: 4.9763e-04 - val_loss: 0.0013 - val_mse: 0.0013\n",
      "Epoch 205/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 4.8337e-04 - mse: 4.8337e-04\n",
      "Epoch 205: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.2177e-04 - mse: 4.2177e-04 - val_loss: 0.0014 - val_mse: 0.0014\n",
      "Epoch 206/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 5.1866e-04 - mse: 5.1866e-04\n",
      "Epoch 206: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.5477e-04 - mse: 5.5477e-04 - val_loss: 0.0020 - val_mse: 0.0020\n",
      "Epoch 207/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0010 - mse: 0.0010\n",
      "Epoch 207: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.7491e-04 - mse: 8.7491e-04 - val_loss: 0.0017 - val_mse: 0.0017\n",
      "Epoch 208/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 7.0605e-04 - mse: 7.0605e-04\n",
      "Epoch 208: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.7898e-04 - mse: 7.7898e-04 - val_loss: 0.0017 - val_mse: 0.0017\n",
      "Epoch 209/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 6.4899e-04 - mse: 6.4899e-04\n",
      "Epoch 209: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.0296e-04 - mse: 6.0296e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
      "Epoch 210/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 3.1380e-04 - mse: 3.1380e-04\n",
      "Epoch 210: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.8874e-04 - mse: 3.8874e-04 - val_loss: 0.0016 - val_mse: 0.0016\n",
      "Epoch 211/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 8.4624e-04 - mse: 8.4624e-04\n",
      "Epoch 211: saving model to My_trained_model.keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.0008e-04 - mse: 7.0008e-04 - val_loss: 0.0022 - val_mse: 0.0022\n",
      "Epoch 212/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 6.7639e-04 - mse: 6.7639e-04\n",
      "Epoch 212: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.3731e-04 - mse: 7.3731e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
      "Epoch 213/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 4.6099e-04 - mse: 4.6099e-04\n",
      "Epoch 213: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.4754e-04 - mse: 8.4754e-04 - val_loss: 0.0032 - val_mse: 0.0032\n",
      "Epoch 214/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0012 - mse: 0.0012\n",
      "Epoch 214: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.0667e-04 - mse: 8.0667e-04 - val_loss: 0.0016 - val_mse: 0.0016\n",
      "Epoch 215/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 4.1110e-04 - mse: 4.1110e-04\n",
      "Epoch 215: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.7711e-04 - mse: 4.7711e-04 - val_loss: 0.0015 - val_mse: 0.0015\n",
      "Epoch 216/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 3.2100e-04 - mse: 3.2100e-04\n",
      "Epoch 216: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.7195e-04 - mse: 3.7195e-04 - val_loss: 0.0014 - val_mse: 0.0014\n",
      "Epoch 217/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 3.7474e-04 - mse: 3.7474e-04\n",
      "Epoch 217: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.4108e-04 - mse: 3.4108e-04 - val_loss: 0.0015 - val_mse: 0.0015\n",
      "Epoch 218/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 3.0420e-04 - mse: 3.0420e-04\n",
      "Epoch 218: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.4319e-04 - mse: 3.4319e-04 - val_loss: 0.0014 - val_mse: 0.0014\n",
      "Epoch 219/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 8.2583e-04 - mse: 8.2583e-04\n",
      "Epoch 219: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.8609e-04 - mse: 5.8609e-04 - val_loss: 0.0017 - val_mse: 0.0017\n",
      "Epoch 220/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 4.8261e-04 - mse: 4.8261e-04\n",
      "Epoch 220: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.7844e-04 - mse: 4.7844e-04 - val_loss: 0.0015 - val_mse: 0.0015\n",
      "Epoch 221/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 5.0391e-04 - mse: 5.0391e-04\n",
      "Epoch 221: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.4621e-04 - mse: 5.4621e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
      "Epoch 222/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0011 - mse: 0.0011\n",
      "Epoch 222: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.3347e-04 - mse: 9.3347e-04 - val_loss: 0.0020 - val_mse: 0.0020\n",
      "Epoch 223/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 8.1010e-04 - mse: 8.1010e-04\n",
      "Epoch 223: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.7903e-04 - mse: 6.7903e-04 - val_loss: 0.0014 - val_mse: 0.0014\n",
      "Epoch 224/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 3.6981e-04 - mse: 3.6981e-04\n",
      "Epoch 224: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.7187e-04 - mse: 4.7187e-04 - val_loss: 0.0015 - val_mse: 0.0015\n",
      "Epoch 225/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 2.7669e-04 - mse: 2.7669e-04\n",
      "Epoch 225: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.6897e-04 - mse: 3.6897e-04 - val_loss: 0.0016 - val_mse: 0.0016\n",
      "Epoch 226/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 9.5077e-04 - mse: 9.5077e-04\n",
      "Epoch 226: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.9839e-04 - mse: 8.9839e-04 - val_loss: 0.0022 - val_mse: 0.0022\n",
      "Epoch 227/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0013 - mse: 0.0013\n",
      "Epoch 227: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.4813e-04 - mse: 8.4813e-04 - val_loss: 0.0016 - val_mse: 0.0016\n",
      "Epoch 228/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 4.0780e-04 - mse: 4.0780e-04\n",
      "Epoch 228: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.3294e-04 - mse: 7.3294e-04 - val_loss: 0.0022 - val_mse: 0.0022\n",
      "Epoch 229/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 5.1673e-04 - mse: 5.1673e-04\n",
      "Epoch 229: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.9033e-04 - mse: 5.9033e-04 - val_loss: 0.0017 - val_mse: 0.0017\n",
      "Epoch 230/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 6.8891e-04 - mse: 6.8891e-04\n",
      "Epoch 230: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.7209e-04 - mse: 5.7209e-04 - val_loss: 0.0020 - val_mse: 0.0020\n",
      "Epoch 231/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 9.0333e-04 - mse: 9.0333e-04\n",
      "Epoch 231: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.9933e-04 - mse: 6.9933e-04 - val_loss: 0.0013 - val_mse: 0.0013\n",
      "Epoch 232/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 4.9207e-04 - mse: 4.9207e-04\n",
      "Epoch 232: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.1467e-04 - mse: 3.1467e-04 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "Epoch 233/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 3.7501e-04 - mse: 3.7501e-04\n",
      "Epoch 233: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.1462e-04 - mse: 3.1462e-04 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "Epoch 234/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 2.5097e-04 - mse: 2.5097e-04\n",
      "Epoch 234: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.1972e-04 - mse: 3.1972e-04 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "Epoch 235/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 1.6615e-04 - mse: 1.6615e-04\n",
      "Epoch 235: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.3699e-04 - mse: 2.3699e-04 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "Epoch 236/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.8074e-04 - mse: 1.8074e-04\n",
      "Epoch 236: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.3809e-04 - mse: 2.3809e-04 - val_loss: 0.0012 - val_mse: 0.0012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 237/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.5144e-04 - mse: 1.5144e-04\n",
      "Epoch 237: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.3301e-04 - mse: 2.3301e-04 - val_loss: 0.0013 - val_mse: 0.0013\n",
      "Epoch 238/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 2.7676e-04 - mse: 2.7676e-04\n",
      "Epoch 238: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.6355e-04 - mse: 2.6355e-04 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "Epoch 239/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 1.1615e-04 - mse: 1.1615e-04\n",
      "Epoch 239: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.2184e-04 - mse: 3.2184e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 240/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 4.7829e-04 - mse: 4.7829e-04\n",
      "Epoch 240: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.8783e-04 - mse: 3.8783e-04 - val_loss: 0.0014 - val_mse: 0.0014\n",
      "Epoch 241/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 4.9280e-04 - mse: 4.9280e-04\n",
      "Epoch 241: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.0840e-04 - mse: 4.0840e-04 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "Epoch 242/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 5.0930e-04 - mse: 5.0930e-04\n",
      "Epoch 242: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.5770e-04 - mse: 4.5770e-04 - val_loss: 0.0017 - val_mse: 0.0017\n",
      "Epoch 243/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 6.2109e-04 - mse: 6.2109e-04\n",
      "Epoch 243: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.1574e-04 - mse: 5.1574e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
      "Epoch 244/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 6.0178e-04 - mse: 6.0178e-04\n",
      "Epoch 244: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.6909e-04 - mse: 4.6909e-04 - val_loss: 0.0010 - val_mse: 0.0010\n",
      "Epoch 245/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 2.4162e-04 - mse: 2.4162e-04\n",
      "Epoch 245: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.2974e-04 - mse: 4.2974e-04 - val_loss: 0.0020 - val_mse: 0.0020\n",
      "Epoch 246/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 4.0919e-04 - mse: 4.0919e-04\n",
      "Epoch 246: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.2610e-04 - mse: 6.2610e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
      "Epoch 247/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 6.6820e-04 - mse: 6.6820e-04\n",
      "Epoch 247: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.0739e-04 - mse: 5.0739e-04 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "Epoch 248/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 3.2510e-04 - mse: 3.2510e-04\n",
      "Epoch 248: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.7886e-04 - mse: 4.7886e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
      "Epoch 249/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 5.3810e-04 - mse: 5.3810e-04\n",
      "Epoch 249: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.6601e-04 - mse: 4.6601e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 250/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 4.5193e-04 - mse: 4.5193e-04\n",
      "Epoch 250: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.5076e-04 - mse: 4.5076e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
      "Epoch 251/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 4.2026e-04 - mse: 4.2026e-04\n",
      "Epoch 251: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.5005e-04 - mse: 4.5005e-04 - val_loss: 0.0013 - val_mse: 0.0013\n",
      "Epoch 252/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 2.2286e-04 - mse: 2.2286e-04\n",
      "Epoch 252: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.9501e-04 - mse: 4.9501e-04 - val_loss: 0.0013 - val_mse: 0.0013\n",
      "Epoch 253/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 2.6211e-04 - mse: 2.6211e-04\n",
      "Epoch 253: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3.9674e-04 - mse: 3.9674e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
      "Epoch 254/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 9.5480e-04 - mse: 9.5480e-04\n",
      "Epoch 254: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.5109e-04 - mse: 6.5109e-04 - val_loss: 0.0013 - val_mse: 0.0013\n",
      "Epoch 255/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 3.9612e-04 - mse: 3.9612e-04\n",
      "Epoch 255: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.3444e-04 - mse: 5.3444e-04 - val_loss: 0.0016 - val_mse: 0.0016\n",
      "Epoch 256/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 7.8719e-04 - mse: 7.8719e-04\n",
      "Epoch 256: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.7455e-04 - mse: 5.7455e-04 - val_loss: 0.0014 - val_mse: 0.0014\n",
      "Epoch 257/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 5.0296e-04 - mse: 5.0296e-04\n",
      "Epoch 257: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.4777e-04 - mse: 4.4777e-04 - val_loss: 0.0015 - val_mse: 0.0015\n",
      "Epoch 258/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 6.1674e-04 - mse: 6.1674e-04\n",
      "Epoch 258: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.9008e-04 - mse: 4.9008e-04 - val_loss: 0.0013 - val_mse: 0.0013\n",
      "Epoch 259/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 3.2136e-04 - mse: 3.2136e-04\n",
      "Epoch 259: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.0385e-04 - mse: 4.0385e-04 - val_loss: 0.0016 - val_mse: 0.0016\n",
      "Epoch 260/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 4.4541e-04 - mse: 4.4541e-04\n",
      "Epoch 260: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.9392e-04 - mse: 5.9392e-04 - val_loss: 0.0017 - val_mse: 0.0017\n",
      "Epoch 261/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 4.4775e-04 - mse: 4.4775e-04\n",
      "Epoch 261: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.8619e-04 - mse: 3.8619e-04 - val_loss: 0.0013 - val_mse: 0.0013\n",
      "Epoch 262/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1.2643e-04 - mse: 1.2643e-04\n",
      "Epoch 262: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.1164e-04 - mse: 3.1164e-04 - val_loss: 0.0014 - val_mse: 0.0014\n",
      "Epoch 263/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 5.6199e-04 - mse: 5.6199e-04\n",
      "Epoch 263: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.7456e-04 - mse: 4.7456e-04 - val_loss: 0.0015 - val_mse: 0.0015\n",
      "Epoch 264/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 3.6185e-04 - mse: 3.6185e-04\n",
      "Epoch 264: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.6000e-04 - mse: 7.6000e-04 - val_loss: 0.0016 - val_mse: 0.0016\n",
      "Epoch 265/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 3.9026e-04 - mse: 3.9026e-04\n",
      "Epoch 265: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.7189e-04 - mse: 5.7189e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
      "Epoch 266/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 8.7523e-04 - mse: 8.7523e-04\n",
      "Epoch 266: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.3573e-04 - mse: 5.3573e-04 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "Epoch 267/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 2.9608e-04 - mse: 2.9608e-04\n",
      "Epoch 267: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.7832e-04 - mse: 3.7832e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
      "Epoch 268/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 3.0341e-04 - mse: 3.0341e-04\n",
      "Epoch 268: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.5468e-04 - mse: 4.5468e-04 - val_loss: 0.0017 - val_mse: 0.0017\n",
      "Epoch 269/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 9.4762e-04 - mse: 9.4762e-04\n",
      "Epoch 269: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.1710e-04 - mse: 8.1710e-04 - val_loss: 0.0020 - val_mse: 0.0020\n",
      "Epoch 270/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0016 - mse: 0.0016\n",
      "Epoch 270: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 0.0034 - val_mse: 0.0034\n",
      "Epoch 271/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0024 - mse: 0.0024\n",
      "Epoch 271: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 0.0041 - val_mse: 0.0041\n",
      "Epoch 272/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0011 - mse: 0.0011\n",
      "Epoch 272: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 0.0028 - val_mse: 0.0028\n",
      "Epoch 273/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0014 - mse: 0.0014\n",
      "Epoch 273: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 0.0046 - val_mse: 0.0046\n",
      "Epoch 274/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0049 - mse: 0.0049\n",
      "Epoch 274: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0034 - mse: 0.0034 - val_loss: 0.0027 - val_mse: 0.0027\n",
      "Epoch 275/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0010 - mse: 0.0010\n",
      "Epoch 275: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0017 - val_mse: 0.0017\n",
      "Epoch 276/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 5.0302e-04 - mse: 5.0302e-04\n",
      "Epoch 276: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.4044e-04 - mse: 4.4044e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 277/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 2.2842e-04 - mse: 2.2842e-04\n",
      "Epoch 277: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.9424e-04 - mse: 2.9424e-04 - val_loss: 0.0017 - val_mse: 0.0017\n",
      "Epoch 278/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 3.0099e-04 - mse: 3.0099e-04\n",
      "Epoch 278: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.7936e-04 - mse: 3.7936e-04 - val_loss: 0.0014 - val_mse: 0.0014\n",
      "Epoch 279/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 3.9229e-04 - mse: 3.9229e-04\n",
      "Epoch 279: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.2251e-04 - mse: 3.2251e-04 - val_loss: 0.0014 - val_mse: 0.0014\n",
      "Epoch 280/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 3.2147e-04 - mse: 3.2147e-04\n",
      "Epoch 280: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.5048e-04 - mse: 2.5048e-04 - val_loss: 0.0013 - val_mse: 0.0013\n",
      "Epoch 281/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.5639e-04 - mse: 1.5639e-04\n",
      "Epoch 281: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.2494e-04 - mse: 2.2494e-04 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "Epoch 282/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.4614e-04 - mse: 1.4614e-04\n",
      "Epoch 282: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.9201e-04 - mse: 1.9201e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 283/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1.3639e-04 - mse: 1.3639e-04\n",
      "Epoch 283: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.9042e-04 - mse: 1.9042e-04 - val_loss: 0.0010 - val_mse: 0.0010\n",
      "Epoch 284/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.6547e-04 - mse: 1.6547e-04\n",
      "Epoch 284: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.9811e-04 - mse: 1.9811e-04 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "Epoch 285/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.5816e-04 - mse: 1.5816e-04\n",
      "Epoch 285: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.8455e-04 - mse: 1.8455e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 286/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 2.0000e-04 - mse: 2.0000e-04\n",
      "Epoch 286: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.9114e-04 - mse: 1.9114e-04 - val_loss: 9.8281e-04 - val_mse: 9.8281e-04\n",
      "Epoch 287/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 1.7948e-04 - mse: 1.7948e-04\n",
      "Epoch 287: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.9659e-04 - mse: 1.9659e-04 - val_loss: 0.0012 - val_mse: 0.0012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 288/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 3.4796e-04 - mse: 3.4796e-04\n",
      "Epoch 288: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.1245e-04 - mse: 3.1245e-04 - val_loss: 9.2967e-04 - val_mse: 9.2967e-04\n",
      "Epoch 289/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.4900e-04 - mse: 1.4900e-04\n",
      "Epoch 289: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5890e-04 - mse: 1.5890e-04 - val_loss: 9.2573e-04 - val_mse: 9.2573e-04\n",
      "Epoch 290/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1.2392e-04 - mse: 1.2392e-04\n",
      "Epoch 290: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.1837e-04 - mse: 2.1837e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 291/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 6.3289e-04 - mse: 6.3289e-04\n",
      "Epoch 291: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.6381e-04 - mse: 3.6381e-04 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "Epoch 292/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 2.1986e-04 - mse: 2.1986e-04\n",
      "Epoch 292: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.4647e-04 - mse: 2.4647e-04 - val_loss: 8.8832e-04 - val_mse: 8.8832e-04\n",
      "Epoch 293/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.1430e-04 - mse: 1.1430e-04\n",
      "Epoch 293: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.8905e-04 - mse: 1.8905e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 294/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 2.6319e-04 - mse: 2.6319e-04\n",
      "Epoch 294: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.0428e-04 - mse: 2.0428e-04 - val_loss: 9.5229e-04 - val_mse: 9.5229e-04\n",
      "Epoch 295/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1.0806e-04 - mse: 1.0806e-04\n",
      "Epoch 295: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.4763e-04 - mse: 2.4763e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 296/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 3.0928e-04 - mse: 3.0928e-04\n",
      "Epoch 296: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.3550e-04 - mse: 3.3550e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 297/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 2.5410e-04 - mse: 2.5410e-04\n",
      "Epoch 297: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.4185e-04 - mse: 3.4185e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
      "Epoch 298/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0014 - mse: 0.0014\n",
      "Epoch 298: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0025 - val_mse: 0.0025\n",
      "Epoch 299/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0010 - mse: 0.0010\n",
      "Epoch 299: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.6452e-04 - mse: 9.6452e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
      "Epoch 300/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 7.2971e-04 - mse: 7.2971e-04\n",
      "Epoch 300: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.7889e-04 - mse: 5.7889e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
      "Epoch 301/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 8.8526e-04 - mse: 8.8526e-04\n",
      "Epoch 301: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.5963e-04 - mse: 8.5963e-04 - val_loss: 0.0015 - val_mse: 0.0015\n",
      "Epoch 302/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 5.3197e-04 - mse: 5.3197e-04\n",
      "Epoch 302: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.9173e-04 - mse: 8.9173e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
      "Epoch 303/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 7.2765e-04 - mse: 7.2765e-04\n",
      "Epoch 303: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.4455e-04 - mse: 9.4455e-04 - val_loss: 0.0028 - val_mse: 0.0028\n",
      "Epoch 304/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0022 - mse: 0.0022\n",
      "Epoch 304: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "Epoch 305/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1.7473e-04 - mse: 1.7473e-04\n",
      "Epoch 305: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.5304e-04 - mse: 2.5304e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 306/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 1.7246e-04 - mse: 1.7246e-04\n",
      "Epoch 306: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.9003e-04 - mse: 1.9003e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 307/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 2.3980e-04 - mse: 2.3980e-04\n",
      "Epoch 307: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.3234e-04 - mse: 2.3234e-04 - val_loss: 8.1904e-04 - val_mse: 8.1904e-04\n",
      "Epoch 308/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.4526e-04 - mse: 1.4526e-04\n",
      "Epoch 308: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.7823e-04 - mse: 1.7823e-04 - val_loss: 9.4295e-04 - val_mse: 9.4295e-04\n",
      "Epoch 309/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1.0143e-04 - mse: 1.0143e-04\n",
      "Epoch 309: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.7198e-04 - mse: 2.7198e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 310/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 4.0523e-04 - mse: 4.0523e-04\n",
      "Epoch 310: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.6743e-04 - mse: 3.6743e-04 - val_loss: 0.0010 - val_mse: 0.0010\n",
      "Epoch 311/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 2.3431e-04 - mse: 2.3431e-04\n",
      "Epoch 311: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.2475e-04 - mse: 3.2475e-04 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "Epoch 312/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1.8148e-04 - mse: 1.8148e-04\n",
      "Epoch 312: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.0772e-04 - mse: 4.0772e-04 - val_loss: 0.0015 - val_mse: 0.0015\n",
      "Epoch 313/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 5.1480e-04 - mse: 5.1480e-04\n",
      "Epoch 313: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.7775e-04 - mse: 7.7775e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
      "Epoch 314/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 5.0774e-04 - mse: 5.0774e-04\n",
      "Epoch 314: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0021 - val_mse: 0.0021\n",
      "Epoch 315/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 7.0015e-04 - mse: 7.0015e-04\n",
      "Epoch 315: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0031 - val_mse: 0.0031\n",
      "Epoch 316/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 316: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0025 - val_mse: 0.0025\n",
      "Epoch 317/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 7.9570e-04 - mse: 7.9570e-04\n",
      "Epoch 317: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0021 - val_mse: 0.0021\n",
      "Epoch 318/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0012 - mse: 0.0012\n",
      "Epoch 318: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.7592e-04 - mse: 6.7592e-04 - val_loss: 0.0015 - val_mse: 0.0015\n",
      "Epoch 319/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 3.0666e-04 - mse: 3.0666e-04\n",
      "Epoch 319: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.7348e-04 - mse: 6.7348e-04 - val_loss: 0.0016 - val_mse: 0.0016\n",
      "Epoch 320/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 4.9419e-04 - mse: 4.9419e-04\n",
      "Epoch 320: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.5791e-04 - mse: 5.5791e-04 - val_loss: 0.0015 - val_mse: 0.0015\n",
      "Epoch 321/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 3.4977e-04 - mse: 3.4977e-04\n",
      "Epoch 321: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.7340e-04 - mse: 3.7340e-04 - val_loss: 0.0010 - val_mse: 0.0010\n",
      "Epoch 322/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 2.2826e-04 - mse: 2.2826e-04\n",
      "Epoch 322: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.9146e-04 - mse: 2.9146e-04 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "Epoch 323/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 6.8567e-04 - mse: 6.8567e-04\n",
      "Epoch 323: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.4861e-04 - mse: 4.4861e-04 - val_loss: 0.0010 - val_mse: 0.0010\n",
      "Epoch 324/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 2.7629e-04 - mse: 2.7629e-04\n",
      "Epoch 324: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.8864e-04 - mse: 2.8864e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 325/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 1.8507e-04 - mse: 1.8507e-04\n",
      "Epoch 325: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.9133e-04 - mse: 1.9133e-04 - val_loss: 9.7536e-04 - val_mse: 9.7536e-04\n",
      "Epoch 326/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1.0964e-04 - mse: 1.0964e-04\n",
      "Epoch 326: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3469e-04 - mse: 1.3469e-04 - val_loss: 8.3217e-04 - val_mse: 8.3217e-04\n",
      "Epoch 327/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 4.7799e-05 - mse: 4.7799e-05\n",
      "Epoch 327: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.6485e-05 - mse: 8.6485e-05 - val_loss: 9.8861e-04 - val_mse: 9.8861e-04\n",
      "Epoch 328/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.3343e-04 - mse: 1.3343e-04\n",
      "Epoch 328: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3611e-04 - mse: 1.3611e-04 - val_loss: 6.9088e-04 - val_mse: 6.9088e-04\n",
      "Epoch 329/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 6.4823e-05 - mse: 6.4823e-05\n",
      "Epoch 329: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2122e-04 - mse: 1.2122e-04 - val_loss: 9.7441e-04 - val_mse: 9.7441e-04\n",
      "Epoch 330/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.5858e-04 - mse: 1.5858e-04\n",
      "Epoch 330: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6320e-04 - mse: 1.6320e-04 - val_loss: 8.8194e-04 - val_mse: 8.8194e-04\n",
      "Epoch 331/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 1.0899e-04 - mse: 1.0899e-04\n",
      "Epoch 331: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3176e-04 - mse: 1.3176e-04 - val_loss: 8.6126e-04 - val_mse: 8.6126e-04\n",
      "Epoch 332/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 8.8720e-05 - mse: 8.8720e-05\n",
      "Epoch 332: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0747e-04 - mse: 1.0747e-04 - val_loss: 9.3439e-04 - val_mse: 9.3439e-04\n",
      "Epoch 333/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.5693e-04 - mse: 1.5693e-04\n",
      "Epoch 333: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6179e-04 - mse: 1.6179e-04 - val_loss: 7.7166e-04 - val_mse: 7.7166e-04\n",
      "Epoch 334/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 2.4889e-04 - mse: 2.4889e-04\n",
      "Epoch 334: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.1990e-04 - mse: 2.1990e-04 - val_loss: 0.0010 - val_mse: 0.0010\n",
      "Epoch 335/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 1.7359e-04 - mse: 1.7359e-04\n",
      "Epoch 335: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.0052e-04 - mse: 2.0052e-04 - val_loss: 9.2106e-04 - val_mse: 9.2106e-04\n",
      "Epoch 336/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.6139e-04 - mse: 1.6139e-04\n",
      "Epoch 336: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.8178e-04 - mse: 2.8178e-04 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "Epoch 337/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 4.4997e-04 - mse: 4.4997e-04\n",
      "Epoch 337: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.4604e-04 - mse: 4.4604e-04 - val_loss: 0.0013 - val_mse: 0.0013\n",
      "Epoch 338/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1.5932e-04 - mse: 1.5932e-04\n",
      "Epoch 338: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.1053e-04 - mse: 3.1053e-04 - val_loss: 0.0015 - val_mse: 0.0015\n",
      "Epoch 339/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 5.9754e-04 - mse: 5.9754e-04\n",
      "Epoch 339: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.7187e-04 - mse: 5.7187e-04 - val_loss: 0.0013 - val_mse: 0.0013\n",
      "Epoch 340/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 1.6707e-04 - mse: 1.6707e-04\n",
      "Epoch 340: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.5337e-04 - mse: 3.5337e-04 - val_loss: 0.0013 - val_mse: 0.0013\n",
      "Epoch 341/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 3.8682e-04 - mse: 3.8682e-04\n",
      "Epoch 341: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.8803e-04 - mse: 3.8803e-04 - val_loss: 8.0908e-04 - val_mse: 8.0908e-04\n",
      "Epoch 342/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 2.1166e-04 - mse: 2.1166e-04\n",
      "Epoch 342: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.0143e-04 - mse: 2.0143e-04 - val_loss: 8.0150e-04 - val_mse: 8.0150e-04\n",
      "Epoch 343/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.5814e-04 - mse: 1.5814e-04\n",
      "Epoch 343: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.0008e-04 - mse: 2.0008e-04 - val_loss: 9.2195e-04 - val_mse: 9.2195e-04\n",
      "Epoch 344/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.7102e-04 - mse: 1.7102e-04\n",
      "Epoch 344: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.1306e-04 - mse: 2.1306e-04 - val_loss: 0.0010 - val_mse: 0.0010\n",
      "Epoch 345/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 3.9410e-04 - mse: 3.9410e-04\n",
      "Epoch 345: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.7589e-04 - mse: 2.7589e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 346/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 3.2446e-04 - mse: 3.2446e-04\n",
      "Epoch 346: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.3958e-04 - mse: 2.3958e-04 - val_loss: 9.9412e-04 - val_mse: 9.9412e-04\n",
      "Epoch 347/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 1.6174e-04 - mse: 1.6174e-04\n",
      "Epoch 347: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.0827e-04 - mse: 3.0827e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 348/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 2.6322e-04 - mse: 2.6322e-04\n",
      "Epoch 348: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.0359e-04 - mse: 2.0359e-04 - val_loss: 8.4719e-04 - val_mse: 8.4719e-04\n",
      "Epoch 349/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 1.3325e-04 - mse: 1.3325e-04\n",
      "Epoch 349: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6799e-04 - mse: 1.6799e-04 - val_loss: 8.6958e-04 - val_mse: 8.6958e-04\n",
      "Epoch 350/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 4.4666e-05 - mse: 4.4666e-05\n",
      "Epoch 350: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3022e-04 - mse: 1.3022e-04 - val_loss: 8.9809e-04 - val_mse: 8.9809e-04\n",
      "Epoch 351/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.2909e-04 - mse: 1.2909e-04\n",
      "Epoch 351: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.3243e-04 - mse: 2.3243e-04 - val_loss: 8.2917e-04 - val_mse: 8.2917e-04\n",
      "Epoch 352/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 1.6753e-04 - mse: 1.6753e-04\n",
      "Epoch 352: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5269e-04 - mse: 1.5269e-04 - val_loss: 8.8261e-04 - val_mse: 8.8261e-04\n",
      "Epoch 353/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 1.8165e-04 - mse: 1.8165e-04\n",
      "Epoch 353: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3492e-04 - mse: 1.3492e-04 - val_loss: 7.9122e-04 - val_mse: 7.9122e-04\n",
      "Epoch 354/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 1.1151e-04 - mse: 1.1151e-04\n",
      "Epoch 354: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.0022e-04 - mse: 2.0022e-04 - val_loss: 9.9889e-04 - val_mse: 9.9889e-04\n",
      "Epoch 355/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 2.5807e-04 - mse: 2.5807e-04\n",
      "Epoch 355: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.5609e-04 - mse: 3.5609e-04 - val_loss: 0.0010 - val_mse: 0.0010\n",
      "Epoch 356/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 2.4406e-04 - mse: 2.4406e-04\n",
      "Epoch 356: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.1296e-04 - mse: 5.1296e-04 - val_loss: 0.0013 - val_mse: 0.0013\n",
      "Epoch 357/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 3.5856e-04 - mse: 3.5856e-04\n",
      "Epoch 357: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.0900e-04 - mse: 4.0900e-04 - val_loss: 0.0015 - val_mse: 0.0015\n",
      "Epoch 358/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 5.1985e-04 - mse: 5.1985e-04\n",
      "Epoch 358: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.4188e-04 - mse: 4.4188e-04 - val_loss: 0.0014 - val_mse: 0.0014\n",
      "Epoch 359/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 5.4799e-04 - mse: 5.4799e-04\n",
      "Epoch 359: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.2600e-04 - mse: 5.2600e-04 - val_loss: 0.0015 - val_mse: 0.0015\n",
      "Epoch 360/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 6.5050e-04 - mse: 6.5050e-04\n",
      "Epoch 360: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.8252e-04 - mse: 6.8252e-04 - val_loss: 0.0016 - val_mse: 0.0016\n",
      "Epoch 361/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 4.3726e-04 - mse: 4.3726e-04\n",
      "Epoch 361: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.9635e-04 - mse: 3.9635e-04 - val_loss: 0.0016 - val_mse: 0.0016\n",
      "Epoch 362/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 4.7179e-04 - mse: 4.7179e-04\n",
      "Epoch 362: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.7491e-04 - mse: 3.7491e-04 - val_loss: 9.7799e-04 - val_mse: 9.7799e-04\n",
      "Epoch 363/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 1.3581e-04 - mse: 1.3581e-04\n",
      "Epoch 363: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5982e-04 - mse: 1.5982e-04 - val_loss: 7.8286e-04 - val_mse: 7.8286e-04\n",
      "Epoch 364/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.3611e-04 - mse: 1.3611e-04\n",
      "Epoch 364: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6440e-04 - mse: 1.6440e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 365/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 2.0911e-04 - mse: 2.0911e-04\n",
      "Epoch 365: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.7869e-04 - mse: 1.7869e-04 - val_loss: 0.0015 - val_mse: 0.0015\n",
      "Epoch 366/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 4.8003e-04 - mse: 4.8003e-04\n",
      "Epoch 366: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.6967e-04 - mse: 3.6967e-04 - val_loss: 9.3612e-04 - val_mse: 9.3612e-04\n",
      "Epoch 367/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 2.1304e-04 - mse: 2.1304e-04\n",
      "Epoch 367: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.5052e-04 - mse: 2.5052e-04 - val_loss: 0.0010 - val_mse: 0.0010\n",
      "Epoch 368/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 4.9084e-04 - mse: 4.9084e-04\n",
      "Epoch 368: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.6368e-04 - mse: 3.6368e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 369/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 2.8917e-04 - mse: 2.8917e-04\n",
      "Epoch 369: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.7010e-04 - mse: 3.7010e-04 - val_loss: 0.0017 - val_mse: 0.0017\n",
      "Epoch 370/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0012 - mse: 0.0012\n",
      "Epoch 370: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.0450e-04 - mse: 8.0450e-04 - val_loss: 0.0022 - val_mse: 0.0022\n",
      "Epoch 371/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0013 - mse: 0.0013\n",
      "Epoch 371: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.2443e-04 - mse: 9.2443e-04 - val_loss: 0.0013 - val_mse: 0.0013\n",
      "Epoch 372/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 5.0528e-04 - mse: 5.0528e-04\n",
      "Epoch 372: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.4930e-04 - mse: 5.4930e-04 - val_loss: 0.0016 - val_mse: 0.0016\n",
      "Epoch 373/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 7.1823e-04 - mse: 7.1823e-04\n",
      "Epoch 373: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.5313e-04 - mse: 7.5313e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 374/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 3.6744e-04 - mse: 3.6744e-04\n",
      "Epoch 374: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.2777e-04 - mse: 4.2777e-04 - val_loss: 0.0017 - val_mse: 0.0017\n",
      "Epoch 375/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 8.8202e-04 - mse: 8.8202e-04\n",
      "Epoch 375: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.0447e-04 - mse: 6.0447e-04 - val_loss: 0.0013 - val_mse: 0.0013\n",
      "Epoch 376/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 2.6806e-04 - mse: 2.6806e-04\n",
      "Epoch 376: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.4257e-04 - mse: 6.4257e-04 - val_loss: 0.0013 - val_mse: 0.0013\n",
      "Epoch 377/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 4.5207e-04 - mse: 4.5207e-04\n",
      "Epoch 377: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.5629e-04 - mse: 3.5629e-04 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "Epoch 378/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 4.6349e-04 - mse: 4.6349e-04\n",
      "Epoch 378: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.3457e-04 - mse: 4.3457e-04 - val_loss: 9.3168e-04 - val_mse: 9.3168e-04\n",
      "Epoch 379/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.9076e-04 - mse: 1.9076e-04\n",
      "Epoch 379: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.3737e-04 - mse: 2.3737e-04 - val_loss: 0.0010 - val_mse: 0.0010\n",
      "Epoch 380/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 2.7599e-04 - mse: 2.7599e-04\n",
      "Epoch 380: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3.7620e-04 - mse: 3.7620e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 381/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 6.4153e-04 - mse: 6.4153e-04\n",
      "Epoch 381: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3.6372e-04 - mse: 3.6372e-04 - val_loss: 9.2084e-04 - val_mse: 9.2084e-04\n",
      "Epoch 382/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 2.3764e-04 - mse: 2.3764e-04\n",
      "Epoch 382: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.3066e-04 - mse: 2.3066e-04 - val_loss: 9.6472e-04 - val_mse: 9.6472e-04\n",
      "Epoch 383/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 2.1093e-04 - mse: 2.1093e-04\n",
      "Epoch 383: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.0849e-04 - mse: 3.0849e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 384/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 2.4989e-04 - mse: 2.4989e-04\n",
      "Epoch 384: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.8854e-04 - mse: 2.8854e-04 - val_loss: 9.5481e-04 - val_mse: 9.5481e-04\n",
      "Epoch 385/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 2.7251e-04 - mse: 2.7251e-04\n",
      "Epoch 385: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.4603e-04 - mse: 2.4603e-04 - val_loss: 8.5808e-04 - val_mse: 8.5808e-04\n",
      "Epoch 386/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 2.3899e-04 - mse: 2.3899e-04\n",
      "Epoch 386: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6735e-04 - mse: 1.6735e-04 - val_loss: 0.0010 - val_mse: 0.0010\n",
      "Epoch 387/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.7074e-04 - mse: 1.7074e-04\n",
      "Epoch 387: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4145e-04 - mse: 1.4145e-04 - val_loss: 6.6841e-04 - val_mse: 6.6841e-04\n",
      "Epoch 388/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 4.6120e-05 - mse: 4.6120e-05\n",
      "Epoch 388: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.5584e-05 - mse: 8.5584e-05 - val_loss: 7.4502e-04 - val_mse: 7.4502e-04\n",
      "Epoch 389/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.0128e-04 - mse: 1.0128e-04\n",
      "Epoch 389: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2699e-04 - mse: 1.2699e-04 - val_loss: 7.8997e-04 - val_mse: 7.8997e-04\n",
      "Epoch 390/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 9.8826e-05 - mse: 9.8826e-05\n",
      "Epoch 390: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.8659e-04 - mse: 1.8659e-04 - val_loss: 8.1074e-04 - val_mse: 8.1074e-04\n",
      "Epoch 391/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1.3198e-04 - mse: 1.3198e-04\n",
      "Epoch 391: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.7719e-04 - mse: 1.7719e-04 - val_loss: 8.8399e-04 - val_mse: 8.8399e-04\n",
      "Epoch 392/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.6608e-04 - mse: 1.6608e-04\n",
      "Epoch 392: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.3765e-04 - mse: 2.3765e-04 - val_loss: 0.0014 - val_mse: 0.0014\n",
      "Epoch 393/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 3.0328e-04 - mse: 3.0328e-04\n",
      "Epoch 393: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.6217e-04 - mse: 2.6217e-04 - val_loss: 8.7786e-04 - val_mse: 8.7786e-04\n",
      "Epoch 394/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 2.7463e-04 - mse: 2.7463e-04\n",
      "Epoch 394: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.2990e-04 - mse: 2.2990e-04 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "Epoch 395/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.6606e-04 - mse: 1.6606e-04\n",
      "Epoch 395: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.7028e-04 - mse: 3.7028e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 396/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 3.4877e-04 - mse: 3.4877e-04\n",
      "Epoch 396: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.6833e-04 - mse: 7.6833e-04 - val_loss: 0.0014 - val_mse: 0.0014\n",
      "Epoch 397/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 7.4842e-04 - mse: 7.4842e-04\n",
      "Epoch 397: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.2692e-04 - mse: 6.2692e-04 - val_loss: 0.0013 - val_mse: 0.0013\n",
      "Epoch 398/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 4.3475e-04 - mse: 4.3475e-04\n",
      "Epoch 398: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.3314e-04 - mse: 4.3314e-04 - val_loss: 0.0013 - val_mse: 0.0013\n",
      "Epoch 399/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 4.6158e-04 - mse: 4.6158e-04\n",
      "Epoch 399: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.1352e-04 - mse: 6.1352e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
      "Epoch 400/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 4.9068e-04 - mse: 4.9068e-04\n",
      "Epoch 400: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0025 - val_mse: 0.0025\n",
      "Epoch 401/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0013 - mse: 0.0013\n",
      "Epoch 401: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0026 - val_mse: 0.0026\n",
      "Epoch 402/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 9.1847e-04 - mse: 9.1847e-04\n",
      "Epoch 402: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0025 - val_mse: 0.0025\n",
      "Epoch 403/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 9.9216e-04 - mse: 9.9216e-04\n",
      "Epoch 403: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0021 - val_mse: 0.0021\n",
      "Epoch 404/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0011 - mse: 0.0011\n",
      "Epoch 404: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0021 - val_mse: 0.0021\n",
      "Epoch 405/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 8.6655e-04 - mse: 8.6655e-04\n",
      "Epoch 405: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0022 - val_mse: 0.0022\n",
      "Epoch 406/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 406: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0026 - val_mse: 0.0026\n",
      "Epoch 407/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0016 - mse: 0.0016\n",
      "Epoch 407: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0017 - val_mse: 0.0017\n",
      "Epoch 408/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 2.6874e-04 - mse: 2.6874e-04\n",
      "Epoch 408: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.4358e-04 - mse: 9.4358e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
      "Epoch 409/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0011 - mse: 0.0011\n",
      "Epoch 409: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.6322e-04 - mse: 6.6322e-04 - val_loss: 0.0017 - val_mse: 0.0017\n",
      "Epoch 410/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 6.3737e-04 - mse: 6.3737e-04\n",
      "Epoch 410: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.3309e-04 - mse: 7.3309e-04 - val_loss: 0.0015 - val_mse: 0.0015\n",
      "Epoch 411/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 4.9127e-04 - mse: 4.9127e-04\n",
      "Epoch 411: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.8171e-04 - mse: 4.8171e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 412/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 2.3945e-04 - mse: 2.3945e-04\n",
      "Epoch 412: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.2270e-04 - mse: 2.2270e-04 - val_loss: 0.0010 - val_mse: 0.0010\n",
      "Epoch 413/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 2.0016e-04 - mse: 2.0016e-04\n",
      "Epoch 413: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.3432e-04 - mse: 2.3432e-04 - val_loss: 0.0011 - val_mse: 0.0011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 414/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1.6742e-04 - mse: 1.6742e-04\n",
      "Epoch 414: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.9227e-04 - mse: 1.9227e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 415/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 2.7670e-04 - mse: 2.7670e-04\n",
      "Epoch 415: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.5861e-04 - mse: 2.5861e-04 - val_loss: 0.0010 - val_mse: 0.0010\n",
      "Epoch 416/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 2.9099e-04 - mse: 2.9099e-04\n",
      "Epoch 416: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.1704e-04 - mse: 2.1704e-04 - val_loss: 9.5476e-04 - val_mse: 9.5476e-04\n",
      "Epoch 417/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 2.0405e-04 - mse: 2.0405e-04\n",
      "Epoch 417: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.0753e-04 - mse: 2.0753e-04 - val_loss: 7.8051e-04 - val_mse: 7.8051e-04\n",
      "Epoch 418/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.2290e-04 - mse: 1.2290e-04\n",
      "Epoch 418: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5584e-04 - mse: 1.5584e-04 - val_loss: 0.0010 - val_mse: 0.0010\n",
      "Epoch 419/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.4039e-04 - mse: 1.4039e-04\n",
      "Epoch 419: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.7510e-04 - mse: 1.7510e-04 - val_loss: 9.8516e-04 - val_mse: 9.8516e-04\n",
      "Epoch 420/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 2.0185e-04 - mse: 2.0185e-04\n",
      "Epoch 420: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.3473e-04 - mse: 2.3473e-04 - val_loss: 0.0010 - val_mse: 0.0010\n",
      "Epoch 421/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 2.2881e-04 - mse: 2.2881e-04\n",
      "Epoch 421: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.9247e-04 - mse: 2.9247e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 422/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.3255e-04 - mse: 1.3255e-04\n",
      "Epoch 422: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.3734e-04 - mse: 2.3734e-04 - val_loss: 0.0010 - val_mse: 0.0010\n",
      "Epoch 423/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.6595e-04 - mse: 1.6595e-04\n",
      "Epoch 423: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.8505e-04 - mse: 1.8505e-04 - val_loss: 8.4988e-04 - val_mse: 8.4988e-04\n",
      "Epoch 424/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 6.9703e-05 - mse: 6.9703e-05\n",
      "Epoch 424: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.6354e-05 - mse: 9.6354e-05 - val_loss: 8.2470e-04 - val_mse: 8.2470e-04\n",
      "Epoch 425/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 5.2982e-05 - mse: 5.2982e-05\n",
      "Epoch 425: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.5342e-05 - mse: 7.5342e-05 - val_loss: 8.0036e-04 - val_mse: 8.0036e-04\n",
      "Epoch 426/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 5.5396e-05 - mse: 5.5396e-05\n",
      "Epoch 426: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.0115e-05 - mse: 8.0115e-05 - val_loss: 7.4974e-04 - val_mse: 7.4974e-04\n",
      "Epoch 427/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 4.8575e-05 - mse: 4.8575e-05\n",
      "Epoch 427: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.5938e-05 - mse: 6.5938e-05 - val_loss: 8.4203e-04 - val_mse: 8.4203e-04\n",
      "Epoch 428/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 1.6113e-04 - mse: 1.6113e-04\n",
      "Epoch 428: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0824e-04 - mse: 1.0824e-04 - val_loss: 7.8641e-04 - val_mse: 7.8641e-04\n",
      "Epoch 429/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 4.4614e-05 - mse: 4.4614e-05\n",
      "Epoch 429: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.9311e-05 - mse: 5.9311e-05 - val_loss: 7.8363e-04 - val_mse: 7.8363e-04\n",
      "Epoch 430/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 3.7883e-05 - mse: 3.7883e-05\n",
      "Epoch 430: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.7761e-05 - mse: 5.7761e-05 - val_loss: 7.6584e-04 - val_mse: 7.6584e-04\n",
      "Epoch 431/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 3.4063e-05 - mse: 3.4063e-05\n",
      "Epoch 431: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.7919e-05 - mse: 6.7919e-05 - val_loss: 7.7447e-04 - val_mse: 7.7447e-04\n",
      "Epoch 432/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 8.0612e-05 - mse: 8.0612e-05\n",
      "Epoch 432: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.5643e-05 - mse: 8.5643e-05 - val_loss: 8.1567e-04 - val_mse: 8.1567e-04\n",
      "Epoch 433/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 6.1553e-05 - mse: 6.1553e-05\n",
      "Epoch 433: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.0975e-05 - mse: 6.0975e-05 - val_loss: 7.2403e-04 - val_mse: 7.2403e-04\n",
      "Epoch 434/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 9.5009e-05 - mse: 9.5009e-05\n",
      "Epoch 434: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.5206e-05 - mse: 6.5206e-05 - val_loss: 7.2344e-04 - val_mse: 7.2344e-04\n",
      "Epoch 435/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 3.9736e-05 - mse: 3.9736e-05\n",
      "Epoch 435: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.1895e-05 - mse: 4.1895e-05 - val_loss: 7.2455e-04 - val_mse: 7.2455e-04\n",
      "Epoch 436/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 4.9021e-05 - mse: 4.9021e-05\n",
      "Epoch 436: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.7189e-05 - mse: 4.7189e-05 - val_loss: 7.9165e-04 - val_mse: 7.9165e-04\n",
      "Epoch 437/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 4.7493e-05 - mse: 4.7493e-05\n",
      "Epoch 437: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.8316e-05 - mse: 5.8316e-05 - val_loss: 8.5457e-04 - val_mse: 8.5457e-04\n",
      "Epoch 438/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1.1953e-04 - mse: 1.1953e-04\n",
      "Epoch 438: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.8272e-05 - mse: 9.8272e-05 - val_loss: 7.6084e-04 - val_mse: 7.6084e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 439/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 7.7843e-05 - mse: 7.7843e-05\n",
      "Epoch 439: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3557e-04 - mse: 1.3557e-04 - val_loss: 8.6264e-04 - val_mse: 8.6264e-04\n",
      "Epoch 440/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 1.7129e-04 - mse: 1.7129e-04\n",
      "Epoch 440: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0359e-04 - mse: 1.0359e-04 - val_loss: 7.8741e-04 - val_mse: 7.8741e-04\n",
      "Epoch 441/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 7.1005e-05 - mse: 7.1005e-05\n",
      "Epoch 441: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.8510e-05 - mse: 8.8510e-05 - val_loss: 7.6182e-04 - val_mse: 7.6182e-04\n",
      "Epoch 442/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.0327e-04 - mse: 1.0327e-04\n",
      "Epoch 442: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.4467e-05 - mse: 9.4467e-05 - val_loss: 8.3615e-04 - val_mse: 8.3615e-04\n",
      "Epoch 443/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.1160e-04 - mse: 1.1160e-04\n",
      "Epoch 443: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0768e-04 - mse: 1.0768e-04 - val_loss: 8.5968e-04 - val_mse: 8.5968e-04\n",
      "Epoch 444/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.3738e-04 - mse: 1.3738e-04\n",
      "Epoch 444: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3874e-04 - mse: 1.3874e-04 - val_loss: 9.7604e-04 - val_mse: 9.7604e-04\n",
      "Epoch 445/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1.5831e-04 - mse: 1.5831e-04\n",
      "Epoch 445: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.7508e-04 - mse: 1.7508e-04 - val_loss: 8.2645e-04 - val_mse: 8.2645e-04\n",
      "Epoch 446/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 2.3808e-04 - mse: 2.3808e-04\n",
      "Epoch 446: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.3919e-04 - mse: 2.3919e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 447/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 2.7845e-04 - mse: 2.7845e-04\n",
      "Epoch 447: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.8314e-04 - mse: 2.8314e-04 - val_loss: 9.2431e-04 - val_mse: 9.2431e-04\n",
      "Epoch 448/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 4.0941e-04 - mse: 4.0941e-04\n",
      "Epoch 448: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.4862e-04 - mse: 2.4862e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 449/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 2.3638e-04 - mse: 2.3638e-04\n",
      "Epoch 449: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.1539e-04 - mse: 4.1539e-04 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "Epoch 450/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 7.1762e-04 - mse: 7.1762e-04\n",
      "Epoch 450: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.5161e-04 - mse: 4.5161e-04 - val_loss: 0.0013 - val_mse: 0.0013\n",
      "Epoch 451/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 4.9052e-04 - mse: 4.9052e-04\n",
      "Epoch 451: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.0829e-04 - mse: 3.0829e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 452/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 3.2459e-04 - mse: 3.2459e-04\n",
      "Epoch 452: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.2305e-04 - mse: 3.2305e-04 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "Epoch 453/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.7224e-04 - mse: 1.7224e-04\n",
      "Epoch 453: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.8535e-04 - mse: 2.8535e-04 - val_loss: 0.0010 - val_mse: 0.0010\n",
      "Epoch 454/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 3.3971e-04 - mse: 3.3971e-04\n",
      "Epoch 454: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.9049e-04 - mse: 2.9049e-04 - val_loss: 0.0013 - val_mse: 0.0013\n",
      "Epoch 455/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 2.1417e-04 - mse: 2.1417e-04\n",
      "Epoch 455: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.5291e-04 - mse: 5.5291e-04 - val_loss: 0.0014 - val_mse: 0.0014\n",
      "Epoch 456/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 5.4509e-04 - mse: 5.4509e-04\n",
      "Epoch 456: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.3305e-04 - mse: 5.3305e-04 - val_loss: 0.0014 - val_mse: 0.0014\n",
      "Epoch 457/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 5.4318e-04 - mse: 5.4318e-04\n",
      "Epoch 457: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.3556e-04 - mse: 8.3556e-04 - val_loss: 0.0013 - val_mse: 0.0013\n",
      "Epoch 458/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 5.7187e-04 - mse: 5.7187e-04\n",
      "Epoch 458: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.8661e-04 - mse: 8.8661e-04 - val_loss: 0.0015 - val_mse: 0.0015\n",
      "Epoch 459/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 6.2803e-04 - mse: 6.2803e-04\n",
      "Epoch 459: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.7905e-04 - mse: 7.7905e-04 - val_loss: 0.0032 - val_mse: 0.0032\n",
      "Epoch 460/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0010 - mse: 0.0010\n",
      "Epoch 460: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0010 - mse: 0.0010 - val_loss: 0.0018 - val_mse: 0.0018\n",
      "Epoch 461/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0010 - mse: 0.0010\n",
      "Epoch 461: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.3989e-04 - mse: 8.3989e-04 - val_loss: 0.0014 - val_mse: 0.0014\n",
      "Epoch 462/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 5.4509e-04 - mse: 5.4509e-04\n",
      "Epoch 462: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.3914e-04 - mse: 5.3914e-04 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "Epoch 463/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 5.1424e-04 - mse: 5.1424e-04\n",
      "Epoch 463: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.6222e-04 - mse: 4.6222e-04 - val_loss: 0.0015 - val_mse: 0.0015\n",
      "Epoch 464/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 6.0984e-04 - mse: 6.0984e-04\n",
      "Epoch 464: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.7104e-04 - mse: 5.7104e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 465/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 2.6597e-04 - mse: 2.6597e-04\n",
      "Epoch 465: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.2809e-04 - mse: 3.2809e-04 - val_loss: 0.0013 - val_mse: 0.0013\n",
      "Epoch 466/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 3.9984e-04 - mse: 3.9984e-04\n",
      "Epoch 466: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.2671e-04 - mse: 3.2671e-04 - val_loss: 0.0010 - val_mse: 0.0010\n",
      "Epoch 467/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 4.0473e-04 - mse: 4.0473e-04\n",
      "Epoch 467: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.6238e-04 - mse: 4.6238e-04 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "Epoch 468/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 5.6474e-04 - mse: 5.6474e-04\n",
      "Epoch 468: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.3684e-04 - mse: 4.3684e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 469/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 4.0906e-04 - mse: 4.0906e-04\n",
      "Epoch 469: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.2667e-04 - mse: 3.2667e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 470/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 2.8378e-04 - mse: 2.8378e-04\n",
      "Epoch 470: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.0852e-04 - mse: 3.0852e-04 - val_loss: 0.0014 - val_mse: 0.0014\n",
      "Epoch 471/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 2.3397e-04 - mse: 2.3397e-04\n",
      "Epoch 471: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.6527e-04 - mse: 3.6527e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 472/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1.8450e-04 - mse: 1.8450e-04\n",
      "Epoch 472: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.5466e-04 - mse: 3.5466e-04 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "Epoch 473/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 6.3632e-04 - mse: 6.3632e-04\n",
      "Epoch 473: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.8990e-04 - mse: 4.8990e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 474/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 4.3906e-04 - mse: 4.3906e-04\n",
      "Epoch 474: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.0853e-04 - mse: 4.0853e-04 - val_loss: 0.0014 - val_mse: 0.0014\n",
      "Epoch 475/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 3.3316e-04 - mse: 3.3316e-04\n",
      "Epoch 475: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.9946e-04 - mse: 2.9946e-04 - val_loss: 8.2897e-04 - val_mse: 8.2897e-04\n",
      "Epoch 476/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1.4130e-04 - mse: 1.4130e-04\n",
      "Epoch 476: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4495e-04 - mse: 1.4495e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 477/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.3330e-04 - mse: 1.3330e-04\n",
      "Epoch 477: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4516e-04 - mse: 1.4516e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 478/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 2.1612e-04 - mse: 2.1612e-04\n",
      "Epoch 478: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.7136e-04 - mse: 1.7136e-04 - val_loss: 0.0010 - val_mse: 0.0010\n",
      "Epoch 479/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 1.0346e-04 - mse: 1.0346e-04\n",
      "Epoch 479: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1268e-04 - mse: 1.1268e-04 - val_loss: 8.3924e-04 - val_mse: 8.3924e-04\n",
      "Epoch 480/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.2061e-04 - mse: 1.2061e-04\n",
      "Epoch 480: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.8716e-05 - mse: 8.8716e-05 - val_loss: 9.8964e-04 - val_mse: 9.8964e-04\n",
      "Epoch 481/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1.0997e-04 - mse: 1.0997e-04\n",
      "Epoch 481: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0219e-04 - mse: 1.0219e-04 - val_loss: 9.4200e-04 - val_mse: 9.4200e-04\n",
      "Epoch 482/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.1277e-04 - mse: 1.1277e-04\n",
      "Epoch 482: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4051e-04 - mse: 1.4051e-04 - val_loss: 9.3645e-04 - val_mse: 9.3645e-04\n",
      "Epoch 483/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1.5149e-04 - mse: 1.5149e-04\n",
      "Epoch 483: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.7834e-04 - mse: 1.7834e-04 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "Epoch 484/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.7713e-04 - mse: 1.7713e-04\n",
      "Epoch 484: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4074e-04 - mse: 1.4074e-04 - val_loss: 8.6645e-04 - val_mse: 8.6645e-04\n",
      "Epoch 485/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 9.5371e-05 - mse: 9.5371e-05\n",
      "Epoch 485: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0109e-04 - mse: 1.0109e-04 - val_loss: 9.5250e-04 - val_mse: 9.5250e-04\n",
      "Epoch 486/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 6.9495e-05 - mse: 6.9495e-05\n",
      "Epoch 486: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.3838e-05 - mse: 7.3838e-05 - val_loss: 9.6331e-04 - val_mse: 9.6331e-04\n",
      "Epoch 487/1000\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 1.3993e-04 - mse: 1.3993e-04\n",
      "Epoch 487: saving model to My_trained_model.keras\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1862e-04 - mse: 1.1862e-04 - val_loss: 9.6325e-04 - val_mse: 9.6325e-04\n",
      "<keras.src.callbacks.history.History object at 0x000001E2D1AAD880>\n"
     ]
    }
   ],
   "source": [
    "h = model.fit(X_train , y_train, epochs=1000,\n",
    "             validation_data=(X_valid, y_valid),\n",
    "             callbacks=[model_checkpoint,early_stopping])\n",
    "# h = model.fit(X_train , y_train, epochs=200,\n",
    "#              validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "16f220b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(h.history['loss'], \"+-\", label='training', color = \"salmon\")\n",
    "plt.plot(h.history['val_loss'], \"+-\", label='validation', color = \"skyblue\")\n",
    "plt.legend(fontsize=10) \n",
    "plt.title('Feed Forward')\n",
    "plt.grid()\n",
    "plt.xlabel('Training epochs', fontsize=11)\n",
    "plt.ylabel('Mean absolute error', fontsize=11)\n",
    "plt.xlim(0, 500)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "708b50a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(h.history['mse'], \"+-\", label='training', color = \"salmon\")\n",
    "plt.plot(h.history['val_mse'], \"+-\", label='validation', color = 'skyblue')\n",
    "plt.legend(fontsize=10) \n",
    "plt.title('Feed Forward')\n",
    "plt.grid()\n",
    "plt.xlabel('Training epochs', fontsize=11)\n",
    "plt.ylabel('Mean squared error', fontsize=11)\n",
    "plt.xlim(0, 500)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4a34d74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from SALib.sample import saltelli\n",
    "from SALib.sample import sobol\n",
    "\n",
    "\n",
    "\n",
    "problem = {\n",
    "    'num_vars': 9,\n",
    "    'names': [ 't','theta','theta_hex','plate_N','plate_hex','l_N','h_N','l_P','h_P' ],\n",
    "    'bounds': [[np.min(data['t']),np.max(data['t'])],\n",
    "              [np.min(data['theta']),np.max(data['theta'])],\n",
    "              [np.min(data['theta_hex']),np.max(data['theta_hex'])],\n",
    "              [np.min(data['plate_N']),np.max(data['plate_N'])],\n",
    "              [np.min(data['plate_hex']),np.max(data['plate_hex'])],\n",
    "              [np.min(data['l_N']),np.max(data['l_N'])],\n",
    "              [np.min(data['h_N']),np.max(data['h_N'])],\n",
    "              [np.min(data['l_P']),np.max(data['l_P'])],\n",
    "              [np.min(data['h_P']),np.max(data['h_P'])]]\n",
    "}\n",
    "\n",
    "#If `calc_second_order` is False, the resulting matrix has ``N * (D + 2)`` rows, \n",
    "#where ``D`` is the number of parameters. If `calc_second_order` is `True`, the resulting matrix has ``N * (2D + 2)`` rows.\n",
    "param_values = sobol.sample(problem, 4096, calc_second_order = True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3e1b0459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize to the predefined normal distribution\n",
    "column_names = ['t','theta','theta_hex','plate_N','plate_hex','l_N','h_N','l_P','h_P' ]\n",
    "param_pd = pd.DataFrame(param_values, columns=column_names)\n",
    "\n",
    "param_values=scaler.transform(param_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f9877ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2560/2560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 915us/step\n"
     ]
    }
   ],
   "source": [
    "#Evaluate the value of the response using the trained model\n",
    "Y_k = model.predict(param_values) \n",
    "\n",
    "Y_k= Y_k.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6481efc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fhassani\\AppData\\Roaming\\Python\\Python39\\site-packages\\SALib\\util\\__init__.py:274: FutureWarning: unique with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  names = list(pd.unique(groups))\n"
     ]
    }
   ],
   "source": [
    "# Perform Sobol Analysis\n",
    "\n",
    "from SALib.analyze import sobol\n",
    "\n",
    "Si = sobol.analyze(problem, Y_k)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "eba09ae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Parameters and values\n",
    "parameters = ['t','theta','theta_hex','plate_N','plate_hex','l_N','h_N','l_P','h_P' ]\n",
    "First_order = [first_Si.iloc[0,0], first_Si.iloc[1,0],first_Si.iloc[2,0], first_Si.iloc[3,0],first_Si.iloc[4,0], first_Si.iloc[5,0], first_Si.iloc[6,0], first_Si.iloc[7,0], first_Si.iloc[8,0]]\n",
    "Total_effect = [total_Si.iloc[0,0], total_Si.iloc[1,0],total_Si.iloc[2,0], total_Si.iloc[3,0],total_Si.iloc[4,0], total_Si.iloc[5,0],total_Si.iloc[6,0], total_Si.iloc[7,0], total_Si.iloc[8,0]]\n",
    "\n",
    "# Sort the data by values in descending order\n",
    "sorted_parameters, sorted_First_order , sorted_Total_effect = zip(*sorted(zip(parameters, First_order,Total_effect), key=lambda x: x[2], reverse=True))\n",
    "\n",
    "\n",
    "# Bar width and positions\n",
    "x = np.arange(len(parameters))\n",
    "bar_width = 0.45\n",
    "\n",
    "# Create the bar chart\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "bar1 = ax.bar(x - bar_width / 2, sorted_First_order, bar_width, label='First order', color='skyblue')\n",
    "bar2 = ax.bar(x + bar_width / 2, sorted_Total_effect, bar_width, label='Total effect', color='salmon')\n",
    "\n",
    "# Add labels and title\n",
    "#ax.set_xlabel('Parameters')\n",
    "ax.set_ylabel('Sobol indices')\n",
    "ax.set_title('Sobol Indices')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(sorted_parameters)\n",
    "ax.legend()\n",
    "\n",
    "# Show the chart\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c00dee7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
